

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>The Intuition Behind The Wasserstein Distance - Vincent Herrmann</title>







<meta property="og:locale" content="en">
<meta property="og:site_name" content="Vincent Herrmann">
<meta property="og:title" content="The Intuition Behind The Wasserstein Distance">


  <link rel="canonical" href="http://localhost:4000/wasserstein/">
  <meta property="og:url" content="http://localhost:4000/wasserstein/">



  <meta property="og:description" content="From what I can tell, there is much interest in the recent Wasserstein-GAN paper. I think this is justified, and if you haven’t already, you should definitely read the paper, or at least this excellent summary. In this post, I don’t want to repeat all the technical principals and promised benefits. Instead, we will focus mainly on one detail that is only mentioned quickly, but I think is important to understand: the Kantorovich-Rubinstein duality, or rather a special case of it. This is of course no new result, but the application certainly is.">



  <meta name="twitter:site" content="@idivinci">
  <meta name="twitter:title" content="The Intuition Behind The Wasserstein Distance">
  <meta name="twitter:description" content="From what I can tell, there is much interest in the recent Wasserstein-GAN paper. I think this is justified, and if you haven’t already, you should definitely read the paper, or at least this excellent summary. In this post, I don’t want to repeat all the technical principals and promised benefits. Instead, we will focus mainly on one detail that is only mentioned quickly, but I think is important to understand: the Kantorovich-Rubinstein duality, or rather a special case of it. This is of course no new result, but the application certainly is.">
  <meta name="twitter:url" content="http://localhost:4000/wasserstein/">

  
    <meta name="twitter:card" content="summary">
    
  

  



  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2017-02-11T00:00:00+01:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Vincent Herrmann",
      "url" : "http://localhost:4000",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Vincent Herrmann Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    <!-- start custom head snippets -->

<!-- insert favicons. use http://realfavicongenerator.net/ -->

<!-- end custom head snippets -->
  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="http://localhost:4000/">Vincent Herrmann</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/about/">About</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/piano/">Piano</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/composition/">Composition</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/blog/">Blog</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  



  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="The Intuition Behind The Wasserstein Distance">
    <meta itemprop="description" content="From what I can tell, there is much interest in the recent Wasserstein-GAN paper. I think this is justified, and if you haven’t already, you should definitely read the paper, or at least this excellent summary. In this post, I don’t want to repeat all the technical principals and promised benefits. Instead, we will focus mainly on one detail that is only mentioned quickly, but I think is important to understand: the Kantorovich-Rubinstein duality, or rather a special case of it. This is of course no new result, but the application certainly is.">
    <meta itemprop="datePublished" content="February 11, 2017">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">The Intuition Behind The Wasserstein Distance
</h1>
          
        </header>
      

      <section class="page__content" itemprop="text">
        <p>From what I can tell, there is much interest in the recent Wasserstein-GAN paper. I think this is justified, and if you haven’t already, you should definitely read the paper, or at least this excellent summary. In this post, I don’t want to repeat all the technical principals and promised benefits. Instead, we will focus mainly on one detail that is only mentioned quickly, but I think is important to understand: the Kantorovich-Rubinstein duality, or rather a special case of it. This is of course no new result, but the application certainly is.</p>

<p>The paper cites the book “Optimal Tranport - Old and New” by Fields-Medal winner and french eccentric Cedric Villani, you can download it from his homepage. Great, isn’t it? That’s about a thousand pages targeted at math PHDs and researchers - have fun! Generally, I found it very hard to find material about this topic that gives real explanations but is not bursting with definitions and references to theorems I didn’t know. I hope that maybe this post will fill this gap little bit. These will not be rigorous proofs, and we will generously imply many regularity conditions. But it should be enough get some intuition for this subject.</p>

<p>The argument for our case of the Kantorovich-Rubinstein duality is actually not too complicated and stands for itself. It is, however, very abstract, which is why I decided to start with the discrete case and somewhat related problems in Linear Programming.</p>

<p>First, we will outline the discrete case, and somewhat related problems in Linear Programming. Then we turn to the Wasserstein distance and our case of the Kantorovich-Rubinstein duality. The argument at the end is actually not too complicated and stands for it self. However, it is very abstract</p>

<p>He also talks about this topic in a more approachable way in this interesting talk, but gives no real explanation.</p>

<p>The mathematical concepts behind this application of the Wasserstein distance is quite interesting, and  behind this</p>

<p>For the discriminator in a GAN, we need some way to measure the distance or divergence between the real and the fake data distribution. Usually, some kind of f-divergence or, most notably, the Jensen-Shannon divergence are used. They all have at the basis the quotient of the probability distributions. While they clearly do work, this fact is problematic for highly concentrated distributions (e.g. when the samples all lie on a low-dimensional submanifold). Then we are basically trying to divide by zero, and often get no useful gradient to train the generator, as is shown in the paper.</p>

<p>A more robust way to measure this distance is the Wasserstein-1 metric. Although the idea behind it is simple and intuitive, t</p>

<h2 id="earth-movers-distance">Earth Mover’s Distance</h2>

<p>First we will consider discrete distributions, in this case it is also descriptively called the Earth mover’s distance (EMD). If we imagine the distributions as different heaps of a certain amount of earth, then the EMD is the minimal total amount of work it takes to transform one heap into the other. Work is defined as the amount of earth in a chunk times the distance it was moved. Let’s call our discrete distributions $P_r$ and $P_\theta$, each with $l$ possible states $x$ or $y$ respectively, and take two arbitrary distributions as an example.</p>

<figure class="half ">
  
    
      <img src="http://localhost:4000/images/wasserstein/P_r.png" alt="" />
    
  
    
      <img src="http://localhost:4000/images/wasserstein/P_theta.png" alt="" />
    
  
  
    <figcaption>Fig.1: Probability distribution $P_r$ and $P_\theta$, each with ten states
</figcaption>
  
</figure>

<!--$P_r$
![p_r](/images/discrete_p_r.png)
$P_\theta$
![p_theta](/images/discrete_p_theta.png)-->

<p>Calculating the EMD is in itself an optimization problem: There are infinitely many ways to move the earth around, and we need to find the optimal one. We call the transportation plan that we are trying to find $\gamma(x,y)$. It simply states how we distribute the amount of earth from one place $x$ over the domain of $y$, or vice versa.</p>

<p>To be a valid transportation plan, the constraints $\sum_x \gamma(x,y) = P_r(y)$ and $\sum_y \gamma(x,y) = P_\theta(x)$ must of course apply. This ensures that following this plan yields the correct distributions. Equivalently, we can call $\gamma$ a joined probability distribution and require that $\gamma \in \Pi(P_r, P_\theta)$, where $\Pi(P_r, P_\theta)$ is the set of all distributions whose marginals are $P_r$ or $P_\theta$ respectively. To get the EMD, we have to multiply every value of $\gamma$ with the Euclidian distance between $x$ and $y$. With that, the definition of the Earth mover’s distance is:</p>

<script type="math/tex; mode=display">\mathrm{EMD}(P_r, P_\theta) = \inf_{\gamma \in \Pi} \, \sum\limits_{x,y} \lVert x - y \lVert \gamma (x,y) = \inf_{\gamma \in \Pi} \ \mathbb{E}_{(x,y) \sim \gamma} \lVert x - y \lVert</script>

<p>If you’re not familiar with the expression $\inf$, it stands for <em>infimum</em>, or greatest lower bound. It is simply a slight mathematical variation of the <em>minimum</em>. The opposite is $\sup$ or <em>supremum</em>, roughly meaning <em>maximum</em>, which we will come across soon. We can also set $\mathbf{\Gamma} = \gamma(x,y)$ and $\mathbf{D} = \lVert x - y\lVert$, with $\mathbf{\Gamma}, \mathbf{D} \in \mathbb{R}^{l \times l}$. Now we can write</p>

<script type="math/tex; mode=display">\mathrm{EMD}(P_r, P_\theta) = \inf_{\gamma \in \Pi} \, \langle \mathbf{D}, \mathbf{\Gamma} \rangle_\mathrm{F}</script>

<p>where $\langle , \rangle_\mathrm{F}$ is the Frobenius inner product (sum of all the element-wise products).</p>

<figure class=" ">
  
    
      <img src="http://localhost:4000/images/wasserstein/transport_plan.png" alt="" />
    
  
  
    <figcaption>Fig.2: Transportation plan $\mathbf{\Gamma}$ and distances $\mathbf{D}$
</figcaption>
  
</figure>

<h2 id="linear-programming">Linear Programming</h2>

<p>In the picture above you can see the optimal transport plan $\mathbf{\Gamma}$. It can be calculated using the generic method of Linear Programming (LP). With LP, we can solve problems of a certain canonical form: Find a vector $\mathbf{x} \in \mathbb{R}^n$ that minimizes the cost $z = \mathbf{c}^T \mathbf{x}, \ \mathbf{c} \in \mathbb{R}^n$. Additionally, $\mathbf{x}$ is costrained by the equation $\mathbf{A} \mathbf{x} = \mathbf{b}, \ \mathbf{A} \in \mathbb{R}^{m \times n}, \mathbf{b} \in \mathbb{R}^n$ and $\mathbf{x} \geq \mathbf{0}$.</p>

<p>To cast our problem into this form, we have to flatten $\mathbf{\Gamma}$ and $\mathbf{D}$:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\mathbf{x} &= \mathrm{vec}(\mathbf{\Gamma}) \\
\mathbf{c} &= \mathrm{vec}(\mathbf{D}) \\
\end{align} %]]></script>

<p>This means $n = l^2$. For the constraints, we concatenate the target distributions, which makes $m=2l$:</p>

<script type="math/tex; mode=display">\mathbf{b} = \begin{bmatrix} P_r \\ P_\theta\end{bmatrix}</script>

<p>For $\mathbf{A}$, we have to construct a large sparse binary matrix that picks out the values from $\mathbf{x}$ and sums them to get $\mathbf{b}$. This schematic should make it clear:</p>

<script type="math/tex; mode=display">% <![CDATA[
\newcommand\FixWidth[1]{ \hspace{1.9em} \llap{#1}}

\begin{array}{rc}

&  \left. \left[ \begin{array} {rrrr|rrrr}
\FixWidth{p_r(1)} & \FixWidth{p_r(2)} & \FixWidth{\dots} & \FixWidth{p_r(n)} & \FixWidth{p_g(1)} & \FixWidth{p_g(2)} & \FixWidth{\dots} & \FixWidth{p_g(n)}
\end{array} \right]  \, \right\} \; \mathbf{b} \\ \\

\mathbf{x} \left\{ \begin{bmatrix}
\gamma(1, 1) \\
\gamma(1, 2) \\
\vdots \\ \hline
\gamma(2, 1) \\
\gamma(2, 2) \\
\vdots \\ \hline
\vdots \\ \hline
\gamma(n, 1) \\
\gamma(n, 2) \\
\vdots \\
\end{bmatrix} \right.

& \left. \left[ \begin{array}{rrrr|rrrr}
1 & 0 & \dots & 0 & 1 & 0 & \dots & 0 \cr
1 & 0 & \dots & 0 & 0 & 1 & \dots & 0 \cr
\vdots & \vdots & \dots & \vdots & \vdots & \vdots & \ddots & \vdots \cr \hline
0 & 1 & \dots & 0 & 1 & 0 & \dots & 0 \cr
0 & 1 & \dots & 0 & 0 & 1 & \dots & 0 \cr
\vdots & \vdots & \dots & \vdots & \vdots & \vdots & \ddots & \vdots \cr \hline
\FixWidth{\vdots} & \FixWidth{\vdots} & \FixWidth{\vdots} & \FixWidth{\vdots} & \FixWidth{\vdots} &
\FixWidth{\vdots} & \FixWidth{\vdots} & \FixWidth{\vdots} \cr \hline
0 & 0 & \dots & 1 & 1 & 0 & \dots & 0 \cr
0 & 0 & \dots & 1 & 0 & 1 & \dots & 0 \cr
\vdots & \vdots & \dots & \vdots & \vdots & \vdots & \ddots & \vdots \cr
\end{array} \right] \right\} \mathbf{A}

\end{array} %]]></script>

<p>With that, we can call a standard LP routine, for example <code class="highlighter-rouge">linprog()</code> from scipy.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">linprog</span>

<span class="c"># We construct our A matrix by creating two 3-way tensors,</span>
<span class="c"># and then concatenating and reshaping them</span>
<span class="n">A_r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">))</span>
<span class="n">A_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">l</span><span class="p">):</span>
	<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">l</span><span class="p">):</span>
		<span class="n">A_r</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
		<span class="n">A_t</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">A_r</span><span class="p">,</span> <span class="n">A_t</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">l</span><span class="p">))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">P_r</span><span class="p">,</span> <span class="n">P_t</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

<span class="n">emd</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">linprog</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">A_eq</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">b_eq</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">))</span>
</code></pre>
</div>

<p>Now we have our transference plan, as well as the EMD.</p>

<figure class=" ">
  
    
      <img src="http://localhost:4000/images/wasserstein/earth_move.png" alt="" />
    
  
  
    <figcaption>Fig.3: Optimal transportation between $P_r$ and $P_\theta$
</figcaption>
  
</figure>

<!--![p_r](/images/transfer_plan.png)

![p_r](/images/earth_move.png)-->

<h2 id="dual-form">Dual Form</h2>
<p>Unfortunately, this kind of optimization is not practical in many cases, certainly not in domains where GANs are usually used. In our example, we use a one-dimensional random variable with ten possible states. The number of possible discrete states scales exponentially with the number of dimensions of the input variable. For many applications, e.g. images, the input can easily have thousands of dimensions. Even an approximation of $\gamma$ is then virtually impossible.</p>

<p>But actually we don’t care about $\gamma$. We only want a single number, the EMD. Also, we want to use it to train our generator network, which generates the distribution $P_\theta$. To do this, we must be able to calculate the derivative $\partial \ \mathrm{EMD}(P_r, P_\theta) \over \partial  P_\theta$. Since $P_r$ and $P_\theta$ are only constraints of our optimization, this not possible in any straightforward way.</p>

<p>As it turns out, there is another way of calculating the EMD that is much more convenient. Any LP has two ways, in which the problem can be formulated: The primal form, which we just used, and the dual form.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{array}{c|c}

\mathbf{primal \ form:} & \mathbf{dual \ form:}\\

\begin{array}{rrcl}
\mathrm{minimize} \ & z & = & \ \mathbf{c}^T \mathbf{x}, \\
\mathrm{so \ that} \ & \mathbf{A} \mathbf{x} & = & \ \mathbf{b} \\
\mathrm{and}\  & \mathbf{x} & \geq &\ \mathbf{0}
\end{array} &

\begin{array}{rrcl}
\mathrm{maximize} \ & \tilde{z} & = & \ \mathbf{b}^T \mathbf{y}, \\
\mathrm{so \ that} \ & \mathbf{A}^T \mathbf{y} & \leq & \ \mathbf{c} \\ \\
\end{array}

\end{array} %]]></script>

<p>By changing the relations between the same values, we can turn our minimization problem into a maximization problem. Here the objective $\tilde{z}$ directly depends on $\mathbf{b}$, which contains the our distributions $P_r$ and $P_\theta$. It is easy to see that $\tilde{z}$ is a lower bound of $z$:</p>

<script type="math/tex; mode=display">z = \mathbf{c}^T \mathbf{x} \geq \mathbf{y}^T \mathbf{A} \mathbf{x} = \mathbf{y}^T \mathbf{b} = \tilde{z}</script>

<p>This is called the <em>Weak Duality</em> theorem. As you might have guessed, there also exists a <em>Strong Duality</em> theorem, which states that, should we find an optimal solution for $\tilde{z}$, then $z=\tilde{z}$. Proofing is a bit more complicated and requires Farkas theorem as a intermediate result.</p>

<h3 id="farkas-theorem">Farkas Theorem</h3>

<p>We can see the columns of a matrix $\hat{\mathbf{A}} \in \mathbb{R}^{d \times n}$ as vectors $\mathbf{a}<em>1, \mathbf{a}_2, …, \mathbf{a}_n\in \mathbb{R}^{d}$. The set of all possible linear combinations of these vectors with nonnegative coefficients is a convex cone with its apex (peak) at the origin (note that a convex cone could also potentially cover the whole $\mathbb{R}^{d}$ space). We can combine these coefficients in a vector $\mathbf{x} \in \mathbb{R}^{n}</em>{\geq 0}$.</p>

<p>For a vector $\hat{\mathbf{b}} \in \mathbb{R}^{d}$, there are now exactly two possibilities: Either $\hat{\mathbf{b}}$ is contained in the cone, or not. If $\hat{\mathbf{b}}$ is not contained, then we can fit a hyperplane $h$ that goes through the origin between the convex cone and $\hat{\mathbf{b}}$. We can define it in terms of only its normal vector $\hat{\mathbf{y}} \in \mathbb{R}^{d}$. If a vector $\mathbf{v} \in \mathbb{R}^{d}$ lies on $h$, then $\mathbf{v}^T \hat{\mathbf{y}} = 0$, if $\mathbf{v}$ lies in the upper half-space of $h$ (the same side as $\hat{\mathbf{y}}$), then $\mathbf{v}^T \hat{\mathbf{y}} &gt; 0$ and if $\mathbf{v}$ lies in the lower half-space (the opposite side of $\hat{\mathbf{y}}$), then $\mathbf{v}^T \hat{\mathbf{y}} &lt; 0$. As we specified, if $h$ exists, then  $\hat{\mathbf{b}}$ lies in a different half-sapce than and all vectors $\mathbf{a}_i$.</p>

<!--![p_r](/images/farkas_b_i.png)
![p_r](/images/farkas_b_ii.png)-->

<figure class="half ">
  
    
      <img src="http://localhost:4000/images/wasserstein/farkas_i.png" alt="" />
    
  
    
      <img src="http://localhost:4000/images/wasserstein/farkas_ii.png" alt="" />
    
  
  
    <figcaption>Fig.4: Geometrical view of Farkas theorem: If $\mathbf{b}$ does not lie inside or on the blue cone, then we can fit a hyperplane $h$ between $\mathbf{b}$ and the cone
</figcaption>
  
</figure>

<p>Summarized, exactly one of the following statements is true:</p>

<ul>
  <li>$(1)$ There exists $\mathbf{x} \in \mathbb{R}^{n}$, so that $\hat{\mathbf{A}} \mathbf{x} = \hat{\mathbf{b}}$ and $\mathbf{x} \geq \mathbf{0}$</li>
  <li>$(2)$ There exists $\hat{\mathbf{y}} \in \mathbb{R}^{d}$, so that $\hat{\mathbf{A}}^T \hat{\mathbf{y}} \leq \mathbf{0}$ and $\hat{\mathbf{b}}^T \hat{\mathbf{y}} &gt; 0$</li>
</ul>

<p>This is called Farkas theorem, or Farkas alternatives. There exist slightly different versions and several proofs, but what we showed is sufficient for our purposes.</p>

<h3 id="strong-duality">Strong Duality</h3>

<p>The trick for the second part of this proof is to construct a problem that is related to our original LP forms, but in such a way that $\hat{\mathbf{b}}$ lies right at the edge of the convex cone. Then according to Farkas, for some $\hat{\mathbf{y}}$, the corresponding hyperplane comes arbitrarily close to $\hat{\mathbf{b}}$. From this, in combination with the Weak Duality theorem, we will proof the Strong Duality.</p>

<p>Let the minimal solution to the primal problem be ${z^* } = \mathbf{c}^T \mathbf{x}^{* }$. Then we define</p>

<script type="math/tex; mode=display">\hat{\mathbf{A}} = \begin{bmatrix} \mathbf{A} \\ -\mathbf{c}^T \end{bmatrix}, \ \ \
\hat{\mathbf{b}}_\epsilon = \begin{bmatrix} \mathbf{b} \\ -z^* + \epsilon \end{bmatrix}, \ \ \
\hat{\mathbf{y}} = \begin{bmatrix} \mathbf{y} \\ \alpha \end{bmatrix}</script>

<p>with $\epsilon, \alpha \in \mathbb{R}$. For $\epsilon = 0$, we have Farkas case $(1)$, because $\hat{\mathbf{A}} \mathbf{x}^* = \hat{\mathbf{b}}_0$. For $\epsilon &gt; 0$, there exists no nonnegative solution (because because $z^{* }$ is already minimal) and we have Farkas case $(2)$. That means there exist $\mathbf{y}$ and $\alpha$, such that</p>

<script type="math/tex; mode=display">\begin{bmatrix} \mathbf{A} \\ -\mathbf{c}^T \end{bmatrix}^T
\begin{bmatrix} \mathbf{y} \\ \alpha \end{bmatrix} \leq \mathbf{0}, \ \ \ \
\begin{bmatrix} \mathbf{b} \\ -z^* + \epsilon \end{bmatrix}
\begin{bmatrix} \mathbf{y} \\ \alpha \end{bmatrix} > 0</script>

<p>or equivalently</p>

<script type="math/tex; mode=display">\mathbf{A}^T \mathbf{y} \leq \alpha \mathbf{c}, \ \ \mathbf{b}^T \mathbf{y} > \alpha(z^* - \epsilon).</script>

<p>The way we constructed it, we can find $\hat{\mathbf{y}}$ so that additionally $\hat{\mathbf{b}}_0 \hat{\mathbf{y}} = 0$. Then changing $\epsilon$ to any number greater than $0$ has to result in $\hat{\mathbf{b}}_0 \hat{\mathbf{y}} &gt; 0$. In our specific problem, this is only possible if $\alpha &gt; 0$, because $z^* &gt; 0$. We showed that $\hat{\mathbf{y}}$ is simply the normal vector of a hyperplane, and because of that we can freely scale it to any magnitude greater than zero. If we choose to scale it so that $\alpha = 1$, this means there exists vector $\mathbf{y}$, so that</p>

<script type="math/tex; mode=display">\mathbf{A}^T \mathbf{y} \leq \mathbf{c}, \ \ \mathbf{b}^T \mathbf{y} > z^* - \epsilon.</script>

<p>From that we see that $\tilde{z} = z^* - \epsilon$ for any $\epsilon &gt; 0$ is a feasible value of the objective of our dual problem. From the Weak Duality theorem, we know that $\tilde{z} \leq z^{* }$. We just showed that $\tilde{z}$ can get arbitrarily close to $z^{* }$. This means the optimal (maximal) value of our dual form is also $z^{* }$.</p>

<h3 id="dual-implementation">Dual Implementation</h3>

<p>Now we can use the dual form with good conscience to calculate the EMD. As we showed, the maximal value $\tilde{z}^* = \mathbf{b}^T \mathbf{y}^{* }$ is the EMD. Let’s define</p>

<script type="math/tex; mode=display">\mathbf{y}^* = \begin{bmatrix} \mathbf{f} \\ \mathbf{g} \end{bmatrix}</script>

<p>with $\mathbf{f}, \mathbf{g} \in \mathbb{R}^d$. This means $EMD(P_r, P_\theta) = \mathbf{f}^T P_r + \mathbf{g}^T P_\theta$. Recall the constraints of the dual form: $\mathbf{A}^T \mathbf{y} \leq \mathbf{c}$</p>

<script type="math/tex; mode=display">% <![CDATA[
\newcommand\FixWidth[1]{ \hspace{1.6em} \llap{#1}}

\begin{array}{rc}
&  \left. \left[ \begin{array} {rrr|rrr|r|rrr}
\FixWidth{D_{1,1}} & \FixWidth{D_{1,2}} & \FixWidth{\dots} & \FixWidth{D_{2,1}} & \FixWidth{D_{2,2}} & \FixWidth{\dots} & \FixWidth{\dots} & \FixWidth{D_{n,1}} & \FixWidth{D_{ n,2}} & \FixWidth{\dots}
\end{array} \right]  \, \right\} \; \mathbf{c} \\ \\

\mathbf{y} \left\{ \begin{bmatrix}
f(1) \\
f(2) \\
\vdots \\
f(n) \\ \hline
g(1) \\
g(2) \\
\vdots \\
g(n) \\
\end{bmatrix} \right.

& \left. \;\; \left[ \begin{array} {rrr|rrr|r|rrr}

1 & 1 & \dots & 0 & 0 & \dots & \dots & 0 & 0 & \dots \cr
0 & 0 & \dots & 1 & 1 & \dots & \dots & 0 & 0 & \dots \cr
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \dots & \vdots & \vdots & \vdots  \cr
0 & 0 & \dots & 0 & 0 & \dots & \dots & 1 & 1 & \dots \cr \hline

1 & 0 & \dots & 1 & 0 & \dots & \dots & 1 & 0 & \dots \cr
0 & 1 & \dots & 0 & 1 & \dots & \dots & 0 & 1 & \dots \cr
\vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \dots & \vdots & \vdots & \ddots  \cr
\FixWidth{0} & \FixWidth{0} & \FixWidth{\dots} & \FixWidth{0} & \FixWidth{0} & \FixWidth{\dots} & \FixWidth{\dots} & \FixWidth{0} & \FixWidth{0} & \FixWidth{\dots}
\end{array} \right] \right\} \mathbf{A}^T

\end{array} %]]></script>

<p>We can summarize the constraints as $\mathbf{f}_{i} + \mathbf{g}_{j} \leq \mathbf{D}_{i,j}$. The case $i=j$ yields $\mathbf{g}_{i} \leq -\mathbf{f}_{i}$ for all $i$, because $\mathbf{D}_{i,i} = 0$. Since $P_r$ and $P_\theta$ are nonnegative, to maximize our objective, $\sum_i \mathbf{f}_i - \mathbf{g}_i$ has to be as great as possible. This means for the best $\mathbf{y}$ we have $\mathbf{g} = - \mathbf{f}$, which remains true for all additional constraints: Choosing $\mathbf{g}_i &lt; -\mathbf{f}_i$ would only make sense if it had benefits for values $\mathbf{f}_j$ and $\mathbf{g}_j$ with $j \neq i$. Since $\mathbf{f}_j$ and $\mathbf{g}_j$ remain upper-bounded by the other constraints, this is not the case.</p>

<p>Because $P_r$ and $P_\theta$ are nonnegative, to maximize our objective, $ \sum_{i} \mathbf{f}_{i} - \mathbf{g}_{i}$ has to be as big as possible. We see immediately that $\mathbf{g}_{i} \leq -\mathbf{f}_{i}$ for all $i$, because $D_{i,i} = 0$. This means for the best $\mathbf{y}$ we have $\mathbf{g} = - \mathbf{f}$. The other objectives do not change that, as we will beome clear in the proof for the continuous case. These other constraints now limit the positive and negative slope from one value of $\mathbf{f}$ to the next, or the previous.</p>

<!--![p_r](/images/Dual_Constraints_o.png)
![p_r](/images/Dual_Constraints_f.png)
![p_r](/images/Dual_Constraints_g.png)-->

<figure class="third ">
  
    
      <img src="http://localhost:4000/images/wasserstein/Dual_Constraints_o.png" alt="" />
    
  
    
      <img src="http://localhost:4000/images/wasserstein/Dual_Constraints_f.png" alt="" />
    
  
    
      <img src="http://localhost:4000/images/wasserstein/Dual_Constraints_g.png" alt="" />
    
  
  
    <figcaption>Fig.5: Constraints for the dual solution. Blue and red lines depict the upper bounds for $\mathbf{f}$ and $\mathbf{g}$ respectively. For every $\mathbf{f} \neq \mathbf{g}$, there is a net loss of the optimization function.
</figcaption>
  
</figure>

<p>For $\mathbf{g} = - \mathbf{f}$ the constraints become</p>

<script type="math/tex; mode=display">\mathbf{f}_i - \mathbf{f}_j \leq \mathbf{D}_{i,j}, \ \ \mathbf{f}_i - \mathbf{f}_j \geq -\mathbf{D}_{i,j}.</script>

<p>The implementation is straightforward:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># linprog() can only minimize the cost, because of that,</span>
<span class="c"># we optimize the negative of the objective. Also, we are</span>
<span class="c"># not constrained to nonnegative values.</span>
<span class="n">opt_res</span> <span class="o">=</span> <span class="n">linprog</span><span class="p">(</span><span class="o">-</span><span class="n">b</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">))</span>

<span class="n">emd</span> <span class="o">=</span> <span class="o">-</span><span class="n">opt_res</span><span class="o">.</span><span class="n">fun</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">opt_res</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">d</span><span class="p">]</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">opt_res</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="n">d</span><span class="p">:]</span>
</code></pre>
</div>

<figure class=" ">
  
    
      <img src="http://localhost:4000/images/wasserstein/Scaling_f.png" alt="" />
    
  
  
</figure>

<figure class=" ">
  
    
      <img src="http://localhost:4000/images/wasserstein/Scaling_g.png" alt="" />
    
  
  
    <figcaption>Fig.6: Element-wise multiplication of $\mathbf{f}$ and $P_r$, as well as $\mathbf{g} = -\mathbf{f}$  and $P_\theta.$
</figcaption>
  
</figure>

<h2 id="wasserstein-distance">Wasserstein Distance</h2>

<p>Lastly, we turn to the continuous case.
The analog to the <em>Strong Duality</em> in LP is a special case of the Kantorovich-Rubinstein duality.</p>

<p>Let our continuous distributions be $p_r$ and $p_\theta$, and the joined distribution with marginals $p_r$ and $p_\theta$ be $\pi(p_r, p_\theta)$. Then the Wasserstein-1 distance is defined as</p>

<script type="math/tex; mode=display">W(p_r, p_\theta) = \inf_{\gamma \in \pi} \iint\limits_{x,y} \lVert x - y \lVert \gamma (x,y) \, \mathrm{d} x,y = \inf_{\gamma \in \pi} \mathbb{E}_{x,y \sim \gamma} \left( \lVert x - y \lVert \right).</script>

<p>If we add suitable terms, we can relax the constraints on $\gamma$:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{array}{cl}
W(p_r, p_\theta) & = \inf_{\gamma \in \pi} \mathbb{E}_{x,y \sim \gamma} \left( \lVert x - y \lVert \right) \\

& \begin{array}{cc} = \inf_{\gamma \in \pi}  \mathbb{E}_{x,y \sim \gamma} ( \lVert x - y \lVert & + \; \underbrace{\sup_{f} \mathbb{E}_{s \sim p_r}(f(s)) - \mathbb{E}_{t \sim p_\theta}(f(t)) - \left( f(x) - f(y) \right)}) \\

&= \cases{\begin{align} 0, & \ \ \ \mathrm{if \gamma \in \mathrm{\pi}} \\ + \infty  &  \ \ \ \mathrm{else} \end{align}} \end{array}\\

&= \inf_{\gamma} \ \sup_{f} \ \mathbb{E}_{x,y \sim \gamma} \left( \lVert x - y \lVert +  \mathbb{E}_{s \sim p_r}(f(s)) - \mathbb{E}_{t \sim p_\theta}(f(t)) - \left( f(x) - f(y) \right) \right)
\end{array} %]]></script>

<p>To continue, we have to make use of the minimax-principle, which says that in certain cases we can invert the order of $\inf$ and $\sup$ without changing the outcome. To see that, let</p>

<script type="math/tex; mode=display">W(p_r, p_g) = \inf_{\gamma \in \Pi} \mathbb{E}_{x,y \sim \gamma} \left( \lVert x - y \lVert \right)
= \inf_{\gamma} \int\limits_{x,y} \lVert x - y \lVert \gamma (x,y) \, \mathrm{d} x,y \\
= \inf_{\gamma} \ \mathbb{E}_{x,y \sim \gamma} \left( \lVert x - y \lVert + \sup_{f} \mathbb{E}_{s \sim p_r}(f(s)) - \mathbb{E}_{t \sim p_\theta}(f(t)) - \left( f(x) - f(y) \right) \right) \\
= \inf_{\gamma} \ \sup_{f} \ \mathbb{E}_{x,y \sim \gamma} \left( \lVert x - y \lVert +  \mathbb{E}_{s \sim p_r}(f(s)) - \mathbb{E}_{t \sim p_\theta}(f(t)) - \left( f(x) - f(y) \right) \right) \\
= \sup_{f} \ \inf_{\gamma} \ \mathbb{E}_{x,y \sim \gamma} \left( \lVert x - y \lVert +  \mathbb{E}_{s \sim p_r}(f(s)) - \mathbb{E}_{t \sim p_\theta}(f(t)) - \left( f(x) - f(y) \right) \right) \\
= \sup_{f} \mathbb{E}_{s \sim p_r}(f(s)) - \mathbb{E}_{t \sim p_\theta}(f(t)) + \inf_{\gamma} \ \mathbb{E}_{x,y \sim \gamma} \left( \lVert x - y \lVert - \left( f(x) - f(y) \right)\right)</script>

<hr />

<script type="math/tex; mode=display">% <![CDATA[
\begin{array}{cc}
= \inf_{\gamma} \ \mathbb{E}_{x,y \sim \gamma} ( \lVert x - y \lVert + & \underbrace{\sup_{f} \mathbb{E}_{s \sim p_r}(f(s)) - \mathbb{E}_{t \sim p_\theta}(f(t)) - \left( f(x) - f(y) \right)}) \\
&= \cases{\begin{align} 0, & \ \ \ \mathrm{if \gamma \in \mathrm{\Pi}} \\ + \infty  &  \ \ \ \mathrm{else} \end{align}}
\end{array} \\
= \inf_{\gamma} \ \sup_{f} \ \mathbb{E}_{x,y \sim \gamma} \left( \lVert x - y \lVert +  \mathbb{E}_{s \sim p_r}(f(s)) - \mathbb{E}_{t \sim p_\theta}(f(t)) - \left( f(x) - f(y) \right) \right) \\ %]]></script>

<p>The argument that $\inf_A \sup_B \geq \sup_A \inf_B$ is simple: Any f(a,b) that is optimal for $\inf_B \sup_A$ (“lowest of all maxima”) is automatically allowed as a candidate for the infimum of $\sup_A \inf_A$ (“the greatest of all minima”), but not the other way around.</p>

<p>Let’s take some function $g$ and set $g(\hat{a}, \hat{b}) = \inf_{a \in A} \sup_{\ b \in B} g(a,b)$ and $g(\hat{a}’, \hat{b}’) = \sup_{\ b \in B} \inf_{a \in A} g(a,b)$. For $g(\hat{a}, \hat{b}) &gt; g(\hat{a}’, \hat{b}’)$, at least one of those statements must be true:</p>

<ul>
  <li>$g(\hat{a}+t, \hat{b}) &lt; g(\hat{a}, \hat{b})$ for some $t \neq 0$. This is only possible if $\sup_{\ b \in B} g(a,b)$ is not convex in $a$, because $g(\hat{a}, \hat{b})$ is already an infimum for $\hat{a}$.</li>
  <li>$g(\hat{a}’, \hat{b}’+t) &gt; g(\hat{a}’, \hat{b}’)$ for some $t \neq 0$. This is only possible if $\inf_{\ a \in A} g(a,b)$ is not concave in $b$, because $g(\hat{a}’, \hat{b}’)$ is already a supremum for $\hat{b}’$.</li>
</ul>

<p>This means of course that, if  $\sup_{\ b \in B} g(a,b)$ is convex and $\inf_{\ a \in A} g(a,b)$ is concave, then $g(\hat{a}, \hat{b}) = g(\hat{a}’, \hat{b}’)$, the minimax principle applies. From the underbrace, we already see that the convexity condition is met. Now we can try changing the to $\sup \inf$:</p>

<script type="math/tex; mode=display">% <![CDATA[
\sup_{f} \ \inf_{\gamma} \ \mathbb{E}_{x,y \sim \gamma} \left( \lVert x - y \lVert +  \mathbb{E}_{s \sim p_r}(f(s)) - \mathbb{E}_{t \sim p_\theta}(f(t)) - \left( f(x) - f(y) \right) \right) \\
\begin{array}{cc}
= \sup_{f} \ \mathbb{E}_{s \sim p_r}(f(s)) - \mathbb{E}_{t \sim p_\theta}(f(t)) + & \underbrace{ \inf_{\gamma} \ \mathbb{E}_{x,y \sim \gamma} ( \lVert x - y \lVert - ( f(x) - f(y) )} ) \\
&= \cases{\begin{align} 0, & \ \ \ \mathrm{if} \ \| f \| {}_{L} \leq 1\\ - \infty  &  \ \ \ \mathrm{else} \end{align}}
\end{array} \\ %]]></script>

<p>So the concavity condition is also met, and this expression is equivalent to the $W$, and we have proven that</p>

<script type="math/tex; mode=display">W(p_r, p_\theta) = \sup_{f} \ \mathbb{E}_{s \sim p_r}(f(s)) - \mathbb{E}_{t \sim p_\theta}(f(t)).</script>

<hr />

<p>Let’s take some function $g$ and set $g(\hat{a}, \hat{b}) = \sup_{a \in A} \inf_{\ b \in B} g(a,b)$ and $g(\hat{a}’, \hat{b}’) = \inf_{\ b \in B} \sup_{a \in A} g(a,b)$. For $f(a’,b’) &gt; f(a,b)$, there must be either $f(a + (a’-a), b) &gt; f(a,b)$, which is not possible if $\inf_B f$ is concave in $a$, because $f(a,b)$ is already a supremum for $a$. Or there must be $f(a’, b’ + (b-b’)) &lt; f(a’,b’)$, which is not possible if $\sup_A f$ is convex in $b$, because $f(a’,b’)$ is already an infimum for $b’$. Or, of course, both could apply. Anyway this shows that, if $f$ is concave in $a$ and convex in $b$, then $f(a,b) = f(a’b’)$, which means the minimax principle applies.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{array}{cc}
= \sup_{f} \ \mathbb{E}_{s \sim p_r}(f(s)) - \mathbb{E}_{t \sim p_\theta}(f(t)) + & \underbrace{ \inf_{\gamma} \ \mathbb{E}_{x,y \sim \gamma} ( \lVert x - y \lVert - ( f(x) - f(y) )} ) \\
&= \cases{\begin{align} 0, & \ \ \ \mathrm{if} \ \| f \| {}_{L} \leq 1\\ - \infty  &  \ \ \ \mathrm{else} \end{align}}
\end{array} \\ %]]></script>

<p>then there are two options: It minimal in dimension B, or it is not. If it is, it is considered as a maximum for $$ for is a minimum for A and maximum for B, but then it is</p>

<hr />

<script type="math/tex; mode=display">\mathbf{D} = d_{ij} = \lVert x_i - y_i \lVert \\
EM(p_r, p_g) = \inf_{\gamma} \, \langle D, \Gamma\rangle_\mathrm{F}</script>

<p>Lagrangian:
<script type="math/tex">\min_x \max_\lambda L(x, \lambda) = c^T x + \lambda (Ax-b) \\
\min_y \max_{\alpha, \alpha \geq 0} L(x, \alpha) = -b^T y + \alpha(A^T y - c)</script></p>

<script type="math/tex; mode=display">D_{ij} = \lVert x_i - y_i \lVert \\
EM(p_r, p_g) = \inf_{\gamma} \, \langle D, \Gamma\rangle_\mathrm{F}</script>

<script type="math/tex; mode=display">c = \mathrm{vec}(D) \\
x = \mathrm{vec}(\Gamma)</script>

<p>We can see calculating the EMD as a linear programming problem. We have to flatten our $\gamma$ matrix.</p>

<p>Linear programming is a generic problem of following form: Search for a vector $x$, so that the expression $c^T x$ minimizes.
Additionally there are constrains of the form $A x = b$.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
z = & \ \mathbf{c}^T \mathbf{x} \\
\mathbf{A} \mathbf{x} = & \ \mathbf{b} \\
\mathbf{x} \geq & \ \mathbf{0}
\end{align} %]]></script>

<p>Dual Problem:
<script type="math/tex">% <![CDATA[
\begin{align}
\tilde{z} = & \ \mathbf{b}^T \mathbf{y} \\
\mathbf{A}^T \mathbf{y} \leq & \ \mathbf{c} \\
\end{align} %]]></script></p>

<h2 id="weak-duality">Weak Duality</h2>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
primal: &  &dual: \\
\max z = & \ \mathbf{c}^T \mathbf{x}        \hspace{3em} & \min \tilde{z} = & \ \mathbf{b}^T \mathbf{y} \\
\mathbf{A} \mathbf{x} \leq & \ \mathbf{b}  & \mathbf{A}^T \mathbf{y} \geq & \ \mathbf{c} \\
\mathbf{x} \geq & \ \mathbf{0}
\end{align} %]]></script>

<script type="math/tex; mode=display">z \leq \tilde{z} \\
z = \mathbf{c}^T \mathbf{x} \leq \mathbf{y}^T \mathbf{A} \mathbf{x} \leq \mathbf{b}^T \mathbf{y} = \tilde{z}</script>

<h2 id="strong-duality-1">Strong Duality</h2>
<p>optimal solution for primal program: $\mathbf{x}<em>0$
<script type="math/tex">\mathbf{V} = \mathbf{A}^{-1} \\
\mathbf{y} = \mathbf{c} \ \mathbf{V} \\
\mathbf{y} \ \mathbf{b} = \mathbf{c} \ \mathbf{V} \ \mathbf{b} = \mathbf{c} \ \mathbf{x}_0</script>
__</em>
Only if strong duality holds, this is possible:
<script type="math/tex">% <![CDATA[
\begin{align}
\mathbf{A} \mathbf{x} \leq & \ \mathbf{b} \\
\mathbf{c}^T \mathbf{x} \geq & \ \mathbf{b}^T \mathbf{y}\\
\mathbf{x} \geq & \ \mathbf{0}
\end{align} %]]></script></p>

<p>Or
<script type="math/tex">\begin{bmatrix} -\mathbf{A} \\ \mathbf{c}^T \end{bmatrix} \mathbf{x} \geq
\begin{bmatrix} -\mathbf{b} \\ \mathbf{b}^T \mathbf{y}\end{bmatrix}</script></p>

<p>But let’s assume, that’s impossible, and the strong duality does not hold.</p>

<p>For $\epsilon &gt; 0$, this has no solution:
<script type="math/tex">\begin{bmatrix} \mathbf{A} \\ -\mathbf{c}^T \end{bmatrix} \mathbf{x} \leq
\begin{bmatrix} \mathbf{b} \\ -z-\epsilon \end{bmatrix}</script>
So according to Farkas, there must be a solution to
$$</p>

<p>$$</p>

<p>##Wasserstein distance:</p>

<script type="math/tex; mode=display">W(p_r, p_g) = \inf_{\gamma \in \Pi} \mathbb{E} \left( \lVert x - y \lVert \right)
= \inf_{\gamma} \iint\limits_{x,y} \lVert x - y \lVert \gamma (x,y) \, \mathrm{d} x \, \mathrm{d} y</script>

        
      </section>

      <footer class="page__meta">
        
        




        
          <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Updated:</strong> <time datetime="2017-02-11T00:00:00+01:00">February 11, 2017</time></p>
        
      </footer>

      

      


  <nav class="pagination">
    
      <a href="http://localhost:4000/wavelet-construction-and-spectral-factorization/" class="pagination--pager" title="Wavelets II - Vanishing Moments and Spectral Factorization
">Previous</a>
    
    
      <a href="#" class="pagination--pager disabled">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
      <li><a href="https://twitter.com/idivinci"><i class="fa fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
    
    
    
      <li><a href="http://github.com/vincentherrmann"><i class="fa fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="http://localhost:4000/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2017 Vincent Herrmann. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>
      </footer>
    </div>

    <script src="http://localhost:4000/assets/js/main.min.js"></script>

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script type="text/javascript">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/SVG"],

    "HTML-CSS": {
      minScaleAdjust: 50,
      scale: 90,
      availableFonts: ["TeX"],
      preferredFont: "TeX",
      mtextFontInherit: false,
      matchFontHeight: true,
    },

    tex2jax: {
      inlineMath: [['$','$']]
    }
  });
</script>

<!-- <script src="MathJax.Hub.Config(
  { extensions: ["MatchWebFonts.js"],

  MatchWebFonts: {
    matchFor: {
      "HTML-CSS": true,
      NativeMML: false,
      SVG: false
    },
    fontCheckDelay: 20000,
    fontCheckTimeout: 300 * 1000
  },
  tex2jax: {
    inlineMath: [['\\(','\\)']]
  },

  "HTML-CSS": {
    linebreaks: {
      automatic: true
    },
    scale: 40,
    preferredFont: "TeX",
    mtextFontInherit: true,
    matchFontHeight: true
  }

});" type="text/javascript" ></script> -->




  <script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-84550896-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>






  </body>
</html>
